### Going deeper with convolutions

DOI：10.1109/CVPR.2015.7298594

年份：2014

#### Abstract:

​        作者在本文中提出了一个深度卷积神经网络架构叫做Inception，它是为了在ILSVRC14比赛中进行**图像识别**和**目标检测**的任务。这种架构的特点是更好的改善了网络中的计算资源的利用，可以在**增加网络深度和宽度的情况下而保持计算开支为一个常数**。GoogLeNet是一个22层的网络，作者在分类与检测任务中检测了它的性能。

#### 1.Introduction

​        近年来由于**卷积神经网络**的发展，图像识别和目标检测发展迅速。这些进步不仅是更强大硬件、更大数据集或者更大网络模型，还有一些列新的想法，算法还有改进网络结构。GoogLeNet比AlexNet少12x的参数，但是却比他更精确。目标检测的最大进步不仅仅是更深的网络或者更大的模型，而是将**深度架构**与**计算机视觉**结合，比如像R-CNN一样。

​        另一个重要的因素是我们的算法由于移动和嵌入式计算的发展而变得更加有效。值得注意的本篇文章中的架构是经过思考的，而不仅仅是有一个精确度上的提升。文中设计的架构计算开支可以达到**1.5M次加-乘**，不仅仅是在学术上提高精确度，而且可以推广到真实世界使用。即使在一个很大的数据集上，它也能保持一个合理的开销。

​        “深”有两层含义，一个是“Inception” 模块达到了一个新的水平，另一个是比较直观的意思，网络的深度越来越大。在ILSVRC14上，GoogLeNet的表现确实比目前最先进的网络更出色。

#### 2.Related Work

​        从LeNet5开始，卷积神经网络一般有一个标准的结构--堆叠卷积神经网络（也可以后面跟着正则化或者最大池化），最后是全连接网络。基于基本设计的变体开始在论文中流行起来，并且在基本数据集中表现出色。对于更大的网络，最近的趋势是增大层数和每层中的单元数，并且使用dropout来解决过拟合的问题。

​        尽管担心最大池化会丢失空间精度信息，像AlexNet类似的网络已经用来做定位、检测和人类姿势估计。有些人利用不同规格的过滤器来处理不同大小的图片，像Inception模块类似。然而不像两层固定的模型，Inception中所有模块是学习得到的。此外Inception模块重复多次，就得到了22层的GoogLeNet。

​        Network-in-Network是为了提高神经网络表达力而提出的。当使用卷积神经网络的时候，它会被当做额外的1x1卷积网络放在ReLU激活函数之前，这样可以使它很容易的在CNN整个管道中继承，我们使用了很多这样的网络。在我们的设计中，1x1的网络有双重的目的，最重要的是他可以主要用来实现降维来消除计算瓶颈，否则就会限制我们网络的大小。这样不但可以提高深度，并且可以提高广度而没有性能上的损失。

​        目前最主流的目标检测是R-CNN，它把整个检测问题分为两部分：首先以与类别无关的方式将低级提示（例如颜色和超像素一致性）用于潜在的对象建议，然后使用CNN证实在这些地方的对象类别。这个方法权衡了使用低级线索进行边框的精确度和目前最精确的卷积网络的分类能力。我们改造了一个类似的管道在我们的分类中，但是在两部分都进行了改进，例如多边框预测，并且一套完整的边框建议的分类方法。

#### 3.Motivation

​        最直接的方式是增加深度和广度，但是这样会带来两个问题。

​        更大的网络意味着更多参数，很有可能会过拟合，特别是在训练集有限的情况下。这可能会成为一个很大的瓶颈，因为高质量数据集的创建可能会很艰难并且昂贵，特别是那些需要人类专家才能分辨的那些东西。

​        另一个缺点是是网络规模的扩大会需要大量的计算资源，资源利用不得当很多资源可能会被浪费。因为在实际情况中，计算资源总是有限的，所以不能盲目的增大网络的规模。

​        解决两个问题最基本的方式是使用稀疏连接网络代替全连接网络。此外模仿生物学系统的也会有很多优势因为前人的工作，他们的主要结果表明，当数据集被一个特别大、特别稀疏的神经网络表示的时候，优化网络的拓扑结构就可以通过分析最后一层的激活函数的相互关联的统计和高关联输出的分类神经元而建立起来。即使这种证明需要很严格的条件，但是我们也可以在实际中应用他们。

​        在不利的方面，现在的计算基础设施当涉及在非正态分布的数据结构上的计算的时候是非常无效的。即使算术运算的数量减少了100，查找和缓存未命中的开销仍然占主导地位，以至于切换到稀疏矩阵都不会奏效。通过使用稳定改进的，经过高度调整的数值库，利用底层CPU或GPU硬件的微小细节，可以实现极快的密集矩阵乘法，从而进一步拉大了差距。而且，非均匀的稀疏模型需要更复杂的工程和计算基础结构。当前大多数面向视觉的机器学习系统仅通过使用卷积就在空间域中利用稀疏性。但是，卷积被实现为到较早层中补丁的密集连接的集合。结构的均一性和大量的过滤器以及更大的批量使得可以利用高效的密集计算。

​         这就提出了一个问题，即下一步是否有希望：一种架构，如理论所建议的那样，利用了额外的稀疏性，即使在滤波器级别也是如此，但是通过利用密集矩阵的计算来利用我们当前的硬件。关于稀疏矩阵计算的大量文献表明，将稀疏矩阵聚类为相对密集的子矩阵往往会为稀疏矩阵乘法提供最新的实用性能。 认为不久的将来将采用类似的方法来自动构建非统一的深度学习架构似乎并不为过。

​        Inception体系结构最初是作为第一作者的案例研究进行的，该案例旨在评估复杂网络拓扑构造算法的假设输出，该算法试图逼近[2]所暗示的稀疏结构，用于视觉网络，并通过密集，容易地覆盖假设的结果可用组件。

#### 1.Introduction

#### 1.Introduction

#### 1.Introduction

#### 1.Introduction

